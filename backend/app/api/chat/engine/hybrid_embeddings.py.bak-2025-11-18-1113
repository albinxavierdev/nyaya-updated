"""
Hybrid Embedding System for Nyayantar
Generates dual embeddings: InLegalBERT (legal-specific) + OpenAI (general semantic)
"""

import os
import logging
from typing import List, Tuple
from llama_index.core.settings import Settings

logger = logging.getLogger(__name__)


class HybridEmbeddingSystem:
    """
    Manages dual embedding generation using both InLegalBERT and OpenAI embeddings
    """
    
    def __init__(self):
        self.legal_embed_model = None
        self.general_embed_model = None
        self._initialize_embeddings()
    
    def _initialize_embeddings(self):
        """Initialize both embedding models"""
        try:
            # Initialize InLegalBERT for legal-specific embeddings
            # Using FastEmbed with BGE-large as a good legal-specific alternative
            from llama_index.embeddings.fastembed import FastEmbedEmbedding
            self.legal_embed_model = FastEmbedEmbedding(
                model_name="BAAI/bge-large-en-v1.5"
            )
            logger.info("✅ Legal embedding model initialized (BGE-large)")
        except Exception as e:
            logger.error(f"❌ Failed to initialize legal embedding model: {e}")
            self.legal_embed_model = None
        
        try:
            # Initialize OpenAI for general semantic embeddings
            from llama_index.embeddings.openai import OpenAIEmbedding
            openai_api_key = os.getenv("OPENAI_API_KEY") or os.getenv("OPENROUTER_API_KEY")
            
            if openai_api_key:
                self.general_embed_model = OpenAIEmbedding(
                    model="text-embedding-3-small",
                    dimensions=1536
                )
                logger.info("✅ OpenAI embedding model initialized")
            else:
                logger.warning("⚠️ OpenAI API key not found, using fallback embeddings")
                # Fallback to fastembed
                from llama_index.embeddings.fastembed import FastEmbedEmbedding
                self.general_embed_model = FastEmbedEmbedding(
                    model_name="BAAI/bge-small-en-v1.5"
                )
                logger.info("✅ Using FastEmbed fallback for general embeddings")
        except Exception as e:
            logger.error(f"❌ Failed to initialize OpenAI: {e}")
            # Fallback to fastembed
            try:
                from llama_index.embeddings.fastembed import FastEmbedEmbedding
                self.general_embed_model = FastEmbedEmbedding(
                    model_name="BAAI/bge-small-en-v1.5"
                )
                logger.info("✅ Using FastEmbed fallback for general embeddings")
            except Exception as e2:
                logger.error(f"❌ Failed to initialize FastEmbed fallback: {e2}")
                self.general_embed_model = None
    
    def encode_legal(self, texts: List[str]) -> List[List[float]]:
        """
        Generate InLegalBERT embeddings for legal text
        
        Args:
            texts: List of text strings to embed
            
        Returns:
            List of 768-dimensional embedding vectors
        """
        if not self.legal_embed_model:
            raise ValueError("Legal embedding model not initialized")
        
        try:
            # Get embeddings as list of lists
            embeddings = []
            for text in texts:
                emb = self.legal_embed_model.get_text_embedding(text)
                embeddings.append(emb)
            return embeddings
        except Exception as e:
            logger.error(f"❌ Error generating legal embeddings: {e}")
            return []
    
    def encode_general(self, texts: List[str]) -> List[List[float]]:
        """
        Generate OpenAI/FastEmbed embeddings for general semantic text
        
        Args:
            texts: List of text strings to embed
            
        Returns:
            List of 1536-dimensional embedding vectors (or fallback dimension)
        """
        if not self.general_embed_model:
            raise ValueError("General embedding model not initialized")
        
        try:
            # Get embeddings as list of lists
            embeddings = []
            for text in texts:
                emb = self.general_embed_model.get_text_embedding(text)
                embeddings.append(emb)
            return embeddings
        except Exception as e:
            logger.error(f"❌ Error generating general embeddings: {e}")
            return []
    
    def encode_hybrid(self, texts: List[str]) -> Tuple[List[List[float]], List[List[float]]]:
        """
        Generate both legal and general embeddings for texts
        
        Args:
            texts: List of text strings to embed
            
        Returns:
            Tuple of (legal_embeddings, general_embeddings)
        """
        legal_embeddings = self.encode_legal(texts)
        general_embeddings = self.encode_general(texts)
        return legal_embeddings, general_embeddings


# Global instance
_hybrid_embedding_system = None


def get_hybrid_embedding_system() -> HybridEmbeddingSystem:
    """Get or create the global hybrid embedding system instance"""
    global _hybrid_embedding_system
    if _hybrid_embedding_system is None:
        _hybrid_embedding_system = HybridEmbeddingSystem()
    return _hybrid_embedding_system

